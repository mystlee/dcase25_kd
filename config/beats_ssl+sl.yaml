trainer:
  logger:
      class_path: lightning.pytorch.loggers.TensorBoardLogger
      init_args:
        save_dir: log
        name: beats_finetune
  callbacks:
    - class_path: util.OverrideEpochStepCallback
    - class_path: util.FreezeEncoderFinetuneClassifier
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 1
        monitor: val_acc
        mode: max
        filename: '{epoch}-{val_acc:.4f}'
  max_epochs: 30

ckpt_path: null

model:
  class_path: model.lit_asc.LitAscWithWarmupLinearDownScheduler
  init_args:
    backbone:
      class_path: model.backbones.PretrainedBEATs
      init_args:
          pretrained: model/beats/checkpoints/BEATs_iter3_plus_AS2M.pt
          num_classes: 10
    data_augmentation:
      mix_up:
        class_path: util.MixUp
        init_args:
          alpha: 0.3
      mix_style:
        class_path: util.FreqMixStyle
        init_args:
          alpha: 0.4
          p: 0.8
      spec_aug: null
      # spec_aug:
      #   class_path: util.SpecAugmentation
      #   init_args:
      #     mask_size: 0.2
      #     p: 1.0
      filt_aug:
        class_path: util.FilterAugmentation
        init_args:
          filter_type: "step"
          db_range: [-4, 4]
      add_noise:
        class_path: util.AdditiveNoiseAugmentation
        init_args:
          snrs: [10, 20]
      freq_mask:
        class_path: util.FrequencyMaskAugmentation
        init_args:
          mask_ratio: 16
      time_mask:
        class_path: util.TimeMaskAugmentation
        init_args:
          mask_ratios: [10, 20]
          net_pooling: 2
      frame_shift:
        class_path: util.FrameShiftAugmentation
        init_args:
          net_pooling: 2
      dir_aug:
        class_path: util.DeviceImpulseResponseAugmentation
        init_args:
          path_ir: /database/micIR/
          p: 0.4
    class_label: scene
    domain_label: device
    spec_extractor:
      class_path: util.BEATsMel
      init_args:
        dataset_mean: 15.41663
        dataset_std: 6.55582
    # Optimization
    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 0.00001
        betas:
          - 0.9
          - 0.98
        weight_decay: 0.01
    warmup_len: 4
    down_len: 26
    min_lr: 0.005

data:
  class_path: data.data_module.DCASEDataModuleCached
  init_args:
    # The path to meta files
    meta_dir: data/meta_dcase_2025
    # The path to audio files
    audio_dir: /database/dcase/task1/TAU-urban-acoustic-scenes-2022-mobile-development/
    batch_size: 128
    num_workers: 16
    pin_memory: true
    sampling_rate: 16000
    train_subset: split25

